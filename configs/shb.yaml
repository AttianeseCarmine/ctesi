# configs/shb.yaml
# FILE MODIFICATO PER GENERALIZZAZIONE (CLIP-EBC + LoRA)

# 1. IMPOSTAZIONI DEL MODELLO
model:
  name: '_clip_ebc'
  model_name: 'ViT-B-16'     # Modello backbone di CLIP
  weight_name: 'openai'        # Pesi pre-addestrati
  block_size: 16
  input_size: 448              # NB: SHB usa spesso 768 o 1024, potresti voler cambiare questo
  zero_inflated: True        # Abilita il modulo ZIP

  # === 1.A: GENERALIZZAZIONE (LoRA) ===
  lora: True
  lora_rank: 8
  lora_alpha: 16.
  lora_dropout: 0.1

  # === 1.B: BINS E PROMPTS SEMANTICI ===
  # Bins da bin_config.json["shb"]["16"]
  bins: [
      [0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, "inf"]
    ]
  bin_centers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # 9 Ã¨ un placeholder

  text_prompts:
    # Prompts per il modulo ZIP (maschera zero / non-zero)
    pi:
      - ["a photo of an empty space", "a deserted street", "a sidewalk with no people", "nobody here", "background"]
      - ["a photo of a person", "an image with people", "a crowd", "someone here", "people present"]
    
    # Prompts per il modulo VLM (conteggio), 9 prompts per 9 bin non-zero
    lambda:
      - ["one person"]
      - ["two people"]
      - ["three people"]
      - ["four people"]
      - ["five people"]
      - ["six people"]
      - ["seven people"]
      - ["eight people"]
      - ["nine or more people"] # Bin [9, "inf"]

# 2. IMPOSTAZIONI DEL DATASET (Adattato da SHA)
dataset:
  name: 'SHB' # Nome dataset cambiato
  num_classes: 10
  input_size: 448 # NB: Potresti voler aumentare a 768 o 1024 per SHB
  train_split: 'train'
  eval_split: 'val'
  aug_config: 'aug_config_1'
  multi_scale_eval: False
  eval_input_size: 0

# 3. IMPOSTAZIONI DELLA LOSS (da sha.yaml originale)
loss:
  name: 'zip_nll'
  use_regression: True
  use_classification: True
  use_auxiliary: True
  weight_cls: 0.1
  weight_reg: 1.0
  weight_aux: 0.1
  reg_loss: 'l1'
  aux_loss: 'l1'
  # 'count_bins' rimosso

# 4. IMPOSTAZIONI DI TRAINING (da sha.yaml originale)
train:
  optimizer: 'adamw'
  scheduler: 'cosine'
  lr: 0.0001
  weight_decay: 0.0001
  num_epochs: 2000
  batch_size: 8
  num_workers: 4
  eval_freq: 0.25
  eval_start: 100

# 5. IMPOSTAZIONI DI VALUTAZIONE (da sha.yaml originale)
eval:
  batch_size: 1
  num_workers: 4
  sliding_window: True
  window_size: 512
  stride: 256
  max_num_windows: 20
  max_input_size: 2048