# configs/sha.yaml
# FILE MODIFICATO PER GENERALIZZAZIONE (CLIP-EBC + LoRA)

# 1. IMPOSTAZIONI DEL MODELLO
model:
  name: '_clip_ebc'
  model_name: 'ViT-B-16'     # Modello backbone di CLIP
  weight_name: 'openai'        # Pesi pre-addestrati (es. 'openai', 'laion2b')
  block_size: 16
  input_size: 448              # Deve corrispondere a dataset.input_size
  zero_inflated: True        # Abilita il modulo ZIP

 # === 1.A: GENERALIZZAZIONE (LoRA) ===
  lora: True
  lora_rank: 8
  lora_alpha: 16.
  lora_dropout: 0.1
  
  # === 1.B: NUOVI PARAMETRI DI GATING (per la logica seriale) ===
  pi_thresh: 0.5             # Soglia per la maschera (usa 0.5)
  gate_mode: "multiply"      # Metodo di Gating

  # === 1.C: BINS E PROMPTS SEMANTICI ===
  # (Nessuna modifica richiesta qui, la tua configurazione è già corretta)
  bins: [
      [0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9],
      [10, 10], [11, 12], [13, 14], [15, "inf"]
    ]
  bin_centers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11.5, 13.5, 15] 

  text_prompts:
    pi:
      - ["a photo of an empty space", "a deserted street", "a sidewalk with no people", "nobody here", "background"]
      - ["a photo of a person", "an image with people", "a crowd", "someone here", "people present"]
    lambda:
      - ["one person"]
      - ["two people"]
      - ["three people"]
      - ["four people"]
      - ["five people"]
      - ["six people"]
      - ["seven people"]
      - ["eight people"]
      - ["nine people"]
      - ["ten people"]
      - ["a small group of people"]   # Bin [11, 12]
      - ["a group of people"]         # Bin [13, 14]
      - ["a large crowd of people"]   # Bin [15, "inf"]

# 2. IMPOSTAZIONI DEL DATASET (da sha.yaml originale)
dataset:
  name: 'SHA'
  num_classes: 10 # Non più usato da CLIP-EBC, ma innocuo
  input_size: 448
  train_split: 'train'
  eval_split: 'val'
  aug_config: 'aug_config_1'
  multi_scale_eval: False
  eval_input_size: 0

# 3. IMPOSTAZIONI DELLA LOSS (da sha.yaml originale)
loss:
  name: 'zip_nll'
  use_regression: True
  use_classification: True
  use_auxiliary: True
  weight_cls: 0.1  # Parametro da testare (es. 0.1, 0.5, 1.0)
  weight_reg: 1.0
  weight_aux: 0.1
  reg_loss: 'l1'
  aux_loss: 'l1'
 
# 4. IMPOSTAZIONI DI TRAINING (da sha.yaml originale)

# STADIO 1: Pre-training PI Head (ZIP)
train_stage1:
  optimizer: 'adamw'
  scheduler: 'cosine'
  lr: 0.0001
  weight_decay: 0.0001
  num_epochs: 100 
  batch_size: 8
  num_workers: 4
  # Early stopping non necessario per lo stadio 1

# STADIO 2: Pre-training LAMBDA Head (EBC)
train_stage2:
  optimizer: 'adamw'
  scheduler: 'cosine'
  lr: 0.0001
  weight_decay: 0.0001
  num_epochs: 150
  batch_size: 8
  num_workers: 4
  early_stopping_patience: 20 # <-- NUOVA RIGA: Interrompi dopo 20 val senza miglioramenti

# STADIO 3: Joint Fine-tuning
train_stage3:
  optimizer: 'adamw'
  scheduler: 'cosine'
  lr: 0.00001 
  weight_decay: 0.0001
  num_epochs: 50 
  batch_size: 8
  num_workers: 4
  early_stopping_patience: 10 # <-- NUOVA RIGA: Interrompi dopo 10 val senza miglioramenti


# 5. IMPOSTAZIONI DI VALUTAZIONE (da sha.yaml originale)
eval:
  batch_size: 1
  num_workers: 4
  sliding_window: True
  window_size: 512
  stride: 256
  max_num_windows: 20
  max_input_size: 2048